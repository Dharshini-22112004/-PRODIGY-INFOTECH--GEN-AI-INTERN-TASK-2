{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1VPVppVvdhgWHts4kfEvT-jFwuKhjeVGW",
      "authorship_tag": "ABX9TyMsDJXoILeRJqY5cvM1uTlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharshini-22112004/GEN-AI-INTERN-TASK-2/blob/main/INTERN_TASKS_2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT GENERATION WITH MARKOV CHAINS**\n"
      ],
      "metadata": {
        "id": "a05pbEG66YNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "gEy0l2sCNaTD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text corpus\n",
        "sample_text = \"\"\"\n",
        "In the realm of computer science, algorithms are the essence of problem-solving.\n",
        "They provide a step-by-step procedure to perform calculations, data processing,\n",
        "and automated reasoning tasks. Understanding algorithms is fundamental to the\n",
        "study of computer science and programming.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "uwO5CDFGQP3b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "T2HzPHGPQi3l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text = preprocess_text(sample_text)\n",
        "print(processed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfLZnk4SQzGd",
        "outputId": "4eb80cca-0b0d-4231-952d-adf16a1f449a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in the realm of computer science algorithms are the essence of problemsolving they provide a stepbystep procedure to perform calculations data processing and automated reasoning tasks understanding algorithms is fundamental to the study of computer science and programming\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_markov_chain(text, n=2):\n",
        "    \"\"\"\n",
        "    Builds an n-gram Markov chain from the given text.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): Preprocessed text string.\n",
        "        n (int): The size of n-gram. Defaults to 2 (bigrams).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary representing the Markov chain.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    markov_chain = defaultdict(Counter)\n",
        "\n",
        "    # Loop through the words and build the chain\n",
        "    for i in range(len(words) - n):\n",
        "        # Get the current state (as a tuple of n words)\n",
        "        current_state = tuple(words[i:i+n])\n",
        "        # Get the next word\n",
        "        next_word = words[i + n]\n",
        "        # Update the chain\n",
        "        markov_chain[current_state][next_word] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    for current_state, transitions in markov_chain.items():\n",
        "        total = sum(transitions.values())\n",
        "        for word in transitions:\n",
        "            transitions[word] /= total\n",
        "\n",
        "    return markov_chain\n"
      ],
      "metadata": {
        "id": "mHM3nCvBQ8LO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a bigram (n=2) Markov chain\n",
        "n = 2\n",
        "markov_chain = build_markov_chain(processed_text, n)"
      ],
      "metadata": {
        "id": "FJ3ENXitRGRR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of inspecting the chain\n",
        "for state, transitions in markov_chain.items():\n",
        "    print(f\"{state} -> {dict(transitions)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QObNUnSNRSJw",
        "outputId": "d5d74c1d-7e0a-4c11-feb2-4a3c8723ca70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('in', 'the') -> {'realm': 1.0}\n",
            "('the', 'realm') -> {'of': 1.0}\n",
            "('realm', 'of') -> {'computer': 1.0}\n",
            "('of', 'computer') -> {'science': 1.0}\n",
            "('computer', 'science') -> {'algorithms': 0.5, 'and': 0.5}\n",
            "('science', 'algorithms') -> {'are': 1.0}\n",
            "('algorithms', 'are') -> {'the': 1.0}\n",
            "('are', 'the') -> {'essence': 1.0}\n",
            "('the', 'essence') -> {'of': 1.0}\n",
            "('essence', 'of') -> {'problemsolving': 1.0}\n",
            "('of', 'problemsolving') -> {'they': 1.0}\n",
            "('problemsolving', 'they') -> {'provide': 1.0}\n",
            "('they', 'provide') -> {'a': 1.0}\n",
            "('provide', 'a') -> {'stepbystep': 1.0}\n",
            "('a', 'stepbystep') -> {'procedure': 1.0}\n",
            "('stepbystep', 'procedure') -> {'to': 1.0}\n",
            "('procedure', 'to') -> {'perform': 1.0}\n",
            "('to', 'perform') -> {'calculations': 1.0}\n",
            "('perform', 'calculations') -> {'data': 1.0}\n",
            "('calculations', 'data') -> {'processing': 1.0}\n",
            "('data', 'processing') -> {'and': 1.0}\n",
            "('processing', 'and') -> {'automated': 1.0}\n",
            "('and', 'automated') -> {'reasoning': 1.0}\n",
            "('automated', 'reasoning') -> {'tasks': 1.0}\n",
            "('reasoning', 'tasks') -> {'understanding': 1.0}\n",
            "('tasks', 'understanding') -> {'algorithms': 1.0}\n",
            "('understanding', 'algorithms') -> {'is': 1.0}\n",
            "('algorithms', 'is') -> {'fundamental': 1.0}\n",
            "('is', 'fundamental') -> {'to': 1.0}\n",
            "('fundamental', 'to') -> {'the': 1.0}\n",
            "('to', 'the') -> {'study': 1.0}\n",
            "('the', 'study') -> {'of': 1.0}\n",
            "('study', 'of') -> {'computer': 1.0}\n",
            "('science', 'and') -> {'programming': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(markov_chain, n=2, max_length=50, seed=None):\n",
        "    \"\"\"\n",
        "    Generates text using the provided Markov chain.\n",
        "\n",
        "    Parameters:\n",
        "        markov_chain (dict): The Markov chain model.\n",
        "        n (int): The size of n-gram used in the model.\n",
        "        max_length (int): Maximum number of words to generate.\n",
        "        seed (tuple): Optional starting state.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text string.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        # Randomly choose a starting state\n",
        "        seed = random.choice(list(markov_chain.keys()))\n",
        "    elif seed not in markov_chain:\n",
        "        raise ValueError(\"The provided seed is not in the Markov chain.\")\n",
        "\n",
        "    output_words = list(seed)\n",
        "\n",
        "    for _ in range(max_length - n):\n",
        "        current_state = tuple(output_words[-n:])\n",
        "        possible_next_words = markov_chain.get(current_state)\n",
        "\n",
        "        if not possible_next_words:\n",
        "            # If no possible transitions, end the generation\n",
        "            break\n",
        "\n",
        "        next_words = list(possible_next_words.keys())\n",
        "        probabilities = list(possible_next_words.values())\n",
        "        next_word = random.choices(next_words, weights=probabilities)[0]\n",
        "        output_words.append(next_word)\n",
        "\n",
        "    return ' '.join(output_words)\n"
      ],
      "metadata": {
        "id": "Wo-W_pGqRyWV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text without specifying a seed\n",
        "generated_text = generate_text(markov_chain, n=2, max_length=30)\n",
        "print(\"Generated Text:\\n\", generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLd8zwCTR08G",
        "outputId": "056b3483-e578-4796-db3c-319c69191993"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " data processing and automated reasoning tasks understanding algorithms is fundamental to the study of computer science algorithms are the essence of problemsolving they provide a stepbystep procedure to perform calculations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify a seed for generation\n",
        "seed = ('understanding', 'algorithms')\n",
        "generated_text_with_seed = generate_text(markov_chain, n=2, max_length=20, seed=seed)\n",
        "print(\"Generated Text with Seed:\\n\", generated_text_with_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZbY6pYyR-fq",
        "outputId": "cdff3fd3-03a5-48bb-d961-d153abd52f09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text with Seed:\n",
            " understanding algorithms is fundamental to the study of computer science algorithms are the essence of problemsolving they provide a stepbystep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def build_markov_chain(text, n=2):\n",
        "    words = text.split()\n",
        "    markov_chain = defaultdict(Counter)\n",
        "\n",
        "    # Build the chain\n",
        "    for i in range(len(words) - n):\n",
        "        current_state = tuple(words[i:i+n])\n",
        "        next_word = words[i + n]\n",
        "        markov_chain[current_state][next_word] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    for current_state, transitions in markov_chain.items():\n",
        "        total = sum(transitions.values())\n",
        "        for word in transitions:\n",
        "            transitions[word] /= total\n",
        "\n",
        "    return markov_chain\n",
        "\n",
        "def generate_text(markov_chain, n=2, max_length=50, seed=None):\n",
        "    if seed is None:\n",
        "        seed = random.choice(list(markov_chain.keys()))\n",
        "    elif seed not in markov_chain:\n",
        "        raise ValueError(\"The provided seed is not in the Markov chain.\")\n",
        "\n",
        "    output_words = list(seed)\n",
        "\n",
        "    for _ in range(max_length - n):\n",
        "        current_state = tuple(output_words[-n:])\n",
        "        possible_next_words = markov_chain.get(current_state)\n",
        "\n",
        "        if not possible_next_words:\n",
        "            break\n",
        "\n",
        "        next_words = list(possible_next_words.keys())\n",
        "        probabilities = list(possible_next_words.values())\n",
        "        next_word = random.choices(next_words, weights=probabilities)[0]\n",
        "        output_words.append(next_word)\n",
        "\n",
        "    return ' '.join(output_words)\n",
        "\n",
        "# Sample text corpus\n",
        "sample_text = \"\"\"\n",
        "In the realm of computer science, algorithms are the essence of problem-solving.\n",
        "They provide a step-by-step procedure to perform calculations, data processing,\n",
        "and automated reasoning tasks. Understanding algorithms is fundamental to the\n",
        "study of computer science and programming.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocess the text\n",
        "processed_text = preprocess_text(sample_text)\n",
        "\n",
        "# Build the Markov chain\n",
        "n = 2  # You can change n for different n-grams\n",
        "markov_chain = build_markov_chain(processed_text, n)\n",
        "\n",
        "# Generate text\n",
        "generated_text = generate_text(markov_chain, n, max_length=50)\n",
        "print(\"Generated Text:\\n\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awenhoimSHxJ",
        "outputId": "b764d766-1c39-4eb7-a027-3505fafcd0e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " fundamental to the study of computer science and programming\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text from a file\n",
        "with open('/content/jane-austen-pride-prejudice.txt', 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "# Preprocess and build the chain\n",
        "processed_text = preprocess_text(text_data)\n",
        "markov_chain = build_markov_chain(processed_text, n=3)  # Using trigrams\n",
        "\n",
        "# Generate text\n",
        "generated_text = generate_text(markov_chain, n=3, max_length=100)\n",
        "print(\"Generated Text:\\n\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-DYEu8cVjnl",
        "outputId": "8ed48545-2078-4341-a48a-bbc428b427c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            " though i have still another to add i am no stranger to the particulars of your youngest sisters infamous elopement i know it to be bingley from believing him the kind of girl to do such a thing your mother must have been neglected compared with some families i believe we were but such another man for you if you believed it impossible to be true certainly my dear nobody said there were but such of us as wished to learn never wanted the means we were always encouraged to read and improve himself by such an attention would be\n"
          ]
        }
      ]
    }
  ]
}